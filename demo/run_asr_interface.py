# run_asr_inference.py

import torch
import torchaudio
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
import os
from pydub import AudioSegment
import hgtk
import re
from g2pk import G2p
g2p = G2p()

# warning ë¬¸êµ¬ë“¤ ì§€ìš°ê¸°
import warnings
warnings.filterwarnings("ignore")
import logging
logging.getLogger("transformers").setLevel(logging.ERROR)

# ffmpeg / ffprobe ê²½ë¡œ ìˆ˜ë™ ì§€ì •
os.environ["FFMPEG_BINARY"] = r"C:\FFmpeg\bin\ffmpeg.exe"
os.environ["FFPROBE_BINARY"] = r"C:\FFmpeg\bin\ffprobe.exe"
AudioSegment.converter = r"C:\FFmpeg\bin\ffmpeg.exe"
AudioSegment.ffprobe = r"C:\FFmpeg\bin\ffprobe.exe"

# mp3 â†’ wav ë³€í™˜ í•¨ìˆ˜
def ensure_wav(audio_path: str, target_sampling_rate: int = 16000):
    """
    mp3 íŒŒì¼ì„ wavë¡œ ë³€í™˜í•˜ê³ , wav íŒŒì¼ ê²½ë¡œ ë°˜í™˜.
    """
    if audio_path.endswith(".mp3"):
        wav_path = audio_path.rsplit(".", 1)[0] + ".wav"
        audio = AudioSegment.from_file(audio_path)
        audio = audio.set_frame_rate(target_sampling_rate).set_channels(1)
        audio.export(wav_path, format="wav")
        return wav_path
    return audio_path

# 1. ëª¨ë¸ ì„¤ì •
MODEL_ID = "kresnik/wav2vec2-large-xlsr-korean" 

# 2. ëª¨ë¸ ë¡œë“œ
try:
    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)
    model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)
    print(f"âœ… ëª¨ë¸ '{MODEL_ID}' ë¡œë“œ ì™„ë£Œ.")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# 3. ì˜¤ë””ì˜¤ íŒŒì¼ â†’ numpy ë°°ì—´
def speech_file_to_array_fn(path: str, target_sampling_rate: int = 16000):
    try:
        speech_array, sampling_rate = torchaudio.load(path)
        if sampling_rate != target_sampling_rate:
            resampler = torchaudio.transforms.Resample(
                orig_freq=sampling_rate, new_freq=target_sampling_rate
            )
            speech_array = resampler(speech_array)
        return speech_array.squeeze().numpy()
    except Exception as e:
        print(f"Error loading file {path}: {e}")
        return None

# 4. ASR ì¶”ë¡ 
def transcribe_audio(audio_path: str):
    print(f"\nğŸ”¬ ë¶„ì„ ì‹œì‘: {audio_path}")
    audio_input = speech_file_to_array_fn(audio_path)
    if audio_input is None:
        print("ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨ - None ë°˜í™˜")
        return []
    
    input_values = processor(audio_input, sampling_rate=16000, return_tensors="pt").input_values
    
    with torch.no_grad():
        logits = model(input_values).logits
    predicted_ids = torch.argmax(logits, dim=-1)

    transcription = processor.batch_decode(predicted_ids)[0]
    print(f"ASR ì›ë¬¸: {transcription}")

    child_phoneme_sequence = []
    try:
        # 0. ASR ê²°ê³¼ì—ì„œ ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        temp_transcription = transcription.replace('á´¥', '').strip()

        # 1. í•œê¸€ ìŒì ˆ ì´ì™¸ì˜ ëª¨ë“  ë¬¸ì ì œê±°
        clean_text = re.sub(r'[^ê°€-í£]', '', temp_transcription)

        # 2. í•œê¸€ ìŒì ˆì„ ì´ˆ/ì¤‘/ì¢…ì„±ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ phoneme_sequence ë§Œë“¤ê¸°
        for char in clean_text:
            try:
                # ASRì´ ì¸ì‹í•œ ìŒì ˆì„ ì´ˆ/ì¤‘/ì¢…ì„±ìœ¼ë¡œ ë¶„í•´
                cho, jung, jong = hgtk.letter.decompose(char)
                
                # ì´ˆì„± ì²˜ë¦¬
                if cho != ' ':
                    child_phoneme_sequence.append(f"{cho}_ì´ˆ")
                    
                # ì¤‘ì„± ì²˜ë¦¬
                if jung != ' ':
                    for m in list(jung):
                        child_phoneme_sequence.append(f"{m}_ì¤‘")
                
                # ì¢…ì„± ì²˜ë¦¬ (**ì¶”ê°€ë¨**)
                if jong != '':
                    child_phoneme_sequence.append(f"{jong}_ì¢…")
                else:
                    # ì¢…ì„±ì´ ì—†ëŠ” ê²½ìš° ëª…ì‹œì ìœ¼ë¡œ âˆ…_ì¢… ì¶”ê°€
                    child_phoneme_sequence.append("âˆ…_ì¢…")
                    
            except hgtk.exception.NotHangulException:
                continue
                      
    except Exception as e:
        print(f"ê²½ê³ : hgtk ìëª¨ ë¶„í•´ ì‹¤íŒ¨. ASR ê²°ê³¼ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ì‚¬ìš©: {transcription}, ì˜¤ë¥˜: {e}")
        child_phoneme_sequence = list(re.sub(r'\s+', '', transcription))

    print("------------------------------------------")
    print(f"ìµœì¢… ì¸ì‹ ê²°ê³¼ : {transcription}")
    print(f"ìµœì¢… ì¸ì‹ ê²°ê³¼ (ìŒì†Œì—´ ë¦¬ìŠ¤íŠ¸): {child_phoneme_sequence}") # ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ í™•ì¸
    print("------------------------------------------")
    return child_phoneme_sequence

# 5. í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
TEST_AUDIO_PATH = r"demo\test_audio.mp3"  # ì‹¤ì œ mp3 íŒŒì¼
TEST_AUDIO_PATH = ensure_wav(TEST_AUDIO_PATH)  # mp3 â†’ wav ë³€í™˜

def get_standard_phonemes_with_position_g2pk(target_text: str):
    """
    íƒ€ê²Ÿ í…ìŠ¤íŠ¸(í•œê¸€)ë¥¼ g2pkë¡œ í‘œì¤€ ë°œìŒì„ ë³€í™˜í•œ í›„,
    ì´ˆ/ì¤‘/ì¢…ì„± ìœ„ì¹˜ íƒœê·¸ê°€ ë¶™ì€ í‘œì¤€ ìŒì†Œì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: 'ë‹­ì´' (ë°œìŒ: 'ë‹¬ê¸°') -> ['ã„·_ì´ˆ', 'ã…_ì¤‘', 'ã„¹_ì¢…', 'ã„±_ì´ˆ', 'ã…£_ì¤‘']
    ì˜ˆ: 'ì¢‹ì•„ìš”' (ë°œìŒ: 'ì¡°ì•„ìš”') -> ['ã…ˆ_ì´ˆ', 'ã…—_ì¤‘', 'ã…‡_ì´ˆ', 'ã…_ì¤‘', 'ìš”_ì¤‘']
    """
    standard_phoneme_sequence = []
    
    # 1. g2pkë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ í…ìŠ¤íŠ¸ë¥¼ í‘œì¤€ ë°œìŒ ë¬¸ìì—´ë¡œ ë³€í™˜
    # ì´ ê³¼ì •ì—ì„œ ë„ì–´ì“°ê¸° ë° ìŒìš´ ë³€ë™ì´ ë°˜ì˜ë©ë‹ˆë‹¤.
    # ì˜ˆ: 'ë‹­ì´ ë¨¹ë‹¤' -> 'ë‹¬ê¸° ë¨¹ë”°'
    try:
        # NOTE: g2pkëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë„ì–´ì“°ê¸°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
        standard_pronunciation_text = g2p(target_text)
    except Exception as e:
        print(f"g2pk ë³€í™˜ ì˜¤ë¥˜: {e}")
        return []

    # 2. ë„ì–´ì“°ê¸° ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ìˆœìˆ˜í•œ í•œê¸€ ìŒì ˆë§Œ ë‚¨ê¹€
    # g2pk ê²°ê³¼ëŠ” íŠ¹ìˆ˜ë¬¸ì(ì˜ˆ: !?)ë‚˜ ì˜ì–´ëŠ” ê·¸ëŒ€ë¡œ ë‚¨ê¸°ë¯€ë¡œ, í•œê¸€ ìŒì ˆë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    clean_text = re.sub(r'[^ê°€-í£]', '', standard_pronunciation_text)
    
    for char in clean_text:
        try:
            # hgtk.letter.decompose: 'ê³¼' -> ('ã„±', 'ã…—', 'ã…') 
            cho, jung, jong = hgtk.letter.decompose(char)
            
            # í‘œì¤€ ë°œìŒì´ ì ìš©ëœ í›„ì˜ ì´ˆ/ì¤‘/ì¢…ì„± ë¶„í•´
            
            # ì´ˆì„± ì²˜ë¦¬
            if cho != ' ': # ì´ˆì„±ì´ ìˆëŠ” ê²½ìš°
                standard_phoneme_sequence.append(f"{cho}_ì´ˆ")
                
            # ì¤‘ì„± ì²˜ë¦¬ (ë³µìˆ˜ ì¤‘ì„±, ì¦‰ ì´ì¤‘ëª¨ìŒ í¬í•¨)
            # hgtk ë¶„í•´ ê²°ê³¼ê°€ 3ìë¦¬ì´ë¯€ë¡œ, ì¤‘ì„±(jung)ì€ ëª¨ìŒ í•˜ë‚˜ ë˜ëŠ” ë‘ ê°œ(ì´ì¤‘ëª¨ìŒ)ë¥¼ í¬í•¨
            if jung != ' ':
                # ë³µìˆ˜ ì¤‘ì„±ì„ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
                # ì˜ˆ: 'ã…˜'ëŠ” 'ã…—'ì™€ 'ã…'ë¡œ ë¶„ë¦¬ë˜ì–´ ê°ê° 'ã…—_ì¤‘', 'ã…_ì¤‘'ìœ¼ë¡œ ì²˜ë¦¬
                for m in list(jung):
                    standard_phoneme_sequence.append(f"{m}_ì¤‘")
            
            # ì¢…ì„± ì²˜ë¦¬
            if jong != '':
                standard_phoneme_sequence.append(f"{jong}_ì¢…")
            else:
                # ì¢…ì„±ì´ ì—†ëŠ” ê²½ìš° ëª…ì‹œì ìœ¼ë¡œ âˆ…_ì¢… ì¶”ê°€
                standard_phoneme_sequence.append("âˆ…_ì¢…")
                
        except hgtk.exception.NotHangulException:
            # í•œê¸€ì´ ì•„ë‹Œ ë¬¸ì
            continue
            
    return standard_phoneme_sequence

# 2. Sequence Alignment (Levenshtein DP + ì—­ì¶”ì )
# ----------------------------------------------------
def perform_sequence_alignment_levenshtein(standard_seq, child_seq):
    """
    í‘œì¤€ ìŒì†Œì—´ê³¼ ì•„ë™ ìŒì†Œì—´ì„ ë¹„êµí•˜ì—¬ ì˜¤ë¥˜ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
    Levenshtein ê±°ë¦¬ ê¸°ë°˜ DP + ì—­ì¶”ì ìœ¼ë¡œ ì •í™•í•œ ìœ„ì¹˜ íƒì§€
    """
    len_s = len(standard_seq)
    len_c = len(child_seq)
    
    # 1. DP í…Œì´ë¸” ì´ˆê¸°í™”
    dp = [[0]*(len_c+1) for _ in range(len_s+1)]
    for i in range(len_s+1):
        dp[i][0] = i  # í‘œì¤€ì—ì„œ ì‚­ì œ
    for j in range(len_c+1):
        dp[0][j] = j  # ì•„ë™ì—ì„œ ì‚½ì…
    
    # 2. DP í…Œì´ë¸” ì±„ìš°ê¸°
    for i in range(1, len_s+1):
        for j in range(1, len_c+1):
            if standard_seq[i-1] == child_seq[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = min(
                    dp[i-1][j-1] + 1,  # êµì²´
                    dp[i][j-1] + 1,    # ì‚½ì…
                    dp[i-1][j] + 1     # ì‚­ì œ
                )
    
    # 3. ì—­ì¶”ì 
    i, j = len_s, len_c
    alignment_result = []
    while i > 0 or j > 0:
        if i > 0 and j > 0 and standard_seq[i-1] == child_seq[j-1]:
            alignment_result.append({
                'standard_phoneme': standard_seq[i-1],
                'child_phoneme': child_seq[j-1],
                'label': 'ì •í™•'
            })
            i -= 1
            j -= 1
        elif i > 0 and j > 0 and dp[i][j] == dp[i-1][j-1] + 1:
            alignment_result.append({
                'standard_phoneme': standard_seq[i-1],
                'child_phoneme': child_seq[j-1],
                'label': 'êµì²´'
            })
            i -= 1
            j -= 1
        elif j > 0 and dp[i][j] == dp[i][j-1] + 1:
            alignment_result.append({
                'standard_phoneme': 'âˆ…',
                'child_phoneme': child_seq[j-1],
                'label': 'ì²¨ê°€'
            })
            j -= 1
        elif i > 0 and dp[i][j] == dp[i-1][j] + 1:
            alignment_result.append({
                'standard_phoneme': standard_seq[i-1],
                'child_phoneme': 'âˆ…',
                'label': 'íƒˆë½'
            })
            i -= 1
    
    alignment_result.reverse()  # ì—­ìˆœìœ¼ë¡œ appendí–ˆìœ¼ë¯€ë¡œ ë’¤ì§‘ê¸°
    return alignment_result


def split_phoneme(ph):
    """
    ì…ë ¥: 'ã„±_ì´ˆ' ë˜ëŠ” 'âˆ…'
    ì¶œë ¥: phoneme='ã„±', position='ì´ˆ'
    """
    if ph == 'âˆ…':
        return 'âˆ…', 'ì—†ìŒ'
    if '_' not in ph:
        return ph, 'ë¯¸ì •'
    phoneme, position = ph.split('_')
    return phoneme, position

if __name__ == "__main__":
    print("Wav2Vec 2.0 ASR ì¶”ë¡  ë° ë°œìŒ ì˜¤ë¥˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ íƒ€ê²Ÿ í…ìŠ¤íŠ¸ ì •ì˜ 
    # ì˜ˆë¥¼ ë“¤ì–´, ì•„ë™ì´ "ì‚¬ê³¼"ë¼ëŠ” ë‹¨ì–´ë¥¼ ë°œìŒí•´ì•¼ í•œë‹¤ê³  ê°€ì •
    TARGET_TEXT = "ì‚¬ê³¼"
    
    print(f"\n--- íƒ€ê²Ÿ í…ìŠ¤íŠ¸: '{TARGET_TEXT}' ---")

    # 1. í‘œì¤€ ë°œìŒ ìŒì†Œì—´ ìƒì„±
    standard_phonemes = get_standard_phonemes_with_position_g2pk(TARGET_TEXT)
    print(f"í‘œì¤€ ìŒì†Œì—´ (ìœ„ì¹˜ í¬í•¨): {standard_phonemes}")
    
    # 2. ì•„ë™ ë°œìŒ ASR ì¶”ë¡  ë° ìŒì†Œì—´ ë³€í™˜
    child_phonemes = transcribe_audio(TEST_AUDIO_PATH)
    
    if child_phonemes:
        # 3. Sequence Alignmentë¥¼ í†µí•œ ì˜¤ë¥˜ ë¶„ì„
        print("\n--- Sequence Alignment ë¶„ì„ ì‹œì‘ ---")
        alignment_results = perform_sequence_alignment_levenshtein(standard_phonemes, child_phonemes)
        
        # 4. ë¶„ì„ ê²°ê³¼ ì¶œë ¥ (í‘œ í˜•ì‹)
        print("\n[ ìµœì¢… ë°œìŒ ì˜¤ë¥˜ ë¶„ì„ ê²°ê³¼ ]")
        print("------------------------------------------------------------------------")
        print("{:<15} {:<15} {:<10}".format("í‘œì¤€ ìŒì†Œ", "ì•„ë™ ë°œìŒ", "ì˜¤ë¥˜ ë¼ë²¨"))
        print("------------------------------------------------------------------------")
        
        errors = []
        error_count = 0
        for result in alignment_results:
            std_ph = result['standard_phoneme']
            child_ph = result['child_phoneme']
            label = result['label']

            print("{:<15} {:<15} {:<10}".format(
                std_ph, child_ph, label
            ))

            if label != 'ì •í™•':
                error_count += 1
        
                # ìœ„ì¹˜ ë° ìŒì†Œ ë¶„ë¦¬
                phoneme, position = split_phoneme(child_ph if child_ph != 'âˆ…' else std_ph)

                # errors ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
                errors.append({
                    "standard_phoneme": std_ph,
                    "child_phoneme": child_ph,
                    "position": position,
                    "type": label
                })
                
        print("------------------------------------------------------------------------")
        print(f"ì´ ì˜¤ë¥˜ ê°œìˆ˜: {error_count}")
        for e in errors:
            print(f"- í‘œì¤€ ìŒì†Œ: {e['standard_phoneme']}, ì•„ë™ ìŒì†Œ: {e['child_phoneme']}, "
          f"ìœ„ì¹˜: {e['position']}, ìœ í˜•: {e['type']}")
        
    print("\n--- ë°œìŒ ì˜¤ë¥˜ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ---")